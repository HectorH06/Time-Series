---
title: "forecastingWorkflow"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
library(tidyverse)
library(tsibble)
library(fable)
library(fabletools)
library(feasts)
library(lubridate)
library(slider)
library(plotly)

library(randomForest)
```

You can add options to executable code like this

```{r}
gdp <- tidyquant::tq_get(
  x    = "NGDPRNSAXDCMXQ",
  get  = "economic.data",
  from = "1997-01-01"
)

gdp
```

The `echo: false` option disables the printing of code (only output is displayed).

```{r}
gdp <- gdp |> 
  mutate(date = yearquarter(date)) |> 
  as_tsibble(
    index = date,
    key   = symbol
  )

gdp
```

```{r}
gdp_train <- gdp |> 
  filter_index(. ~ "2020 Q4")

gdp_train
```

```{r}
p <- gdp_train |> 
  autoplot(price) +
  labs(
    title = "Time series plot of the Real GDP for Mexico",
    y = "GDP"
  )
 
ggplotly(p, dynamicTicks = TRUE) |> 
  rangeslider()
```

```{r}
gdp_train |> 
  gg_season(price) |> 
  ggplotly()
```

```{r}
gdp_train |> 
  model(stl = STL(price, robust = TRUE)) |> 
  components() |> 
  autoplot() |> 
  ggplotly()
```

```{r}
gdp_train |> 
  autoplot(log(price)) +
  ggtitle("Log of the Real GDP of Mexico")
```

```{r}
gdp_train |> 
  model(stl = STL(log(price) ~ season(window = "periodic"), robust = TRUE)) |> 
  components() |> 
  autoplot() |> 
  ggplotly()
```

```{r}
gdp_fit <- gdp_train |> 
  model(
    snaive = SNAIVE(log(price)),
    drift  = RW(log(price) ~ drift())
  )
```

```{r}
gdp_fit |> 
  select(snaive) |> 
  gg_tsresiduals() +
  ggtitle("Residuals Diagnostics for the Seasonal Naïve Model")
```

```{r}
gdp_fit |> 
  select(drift) |> 
  gg_tsresiduals() +
  ggtitle("Residuals Diagnostics for the Drift Model")
```

```{r}
gdp_fit |> 
  augment() |> 
  features(.innov, ljung_box, lag = 24, dof = 0)
```

```{r}
gdp_train_accu <- accuracy(gdp_fit) |> 
  arrange(MAPE)
gdp_train_accu |> 
  select(symbol:.type, MAPE, RMSE, MAE, MASE)
```

```{r}
gdp_fit_dcmp <- gdp_train |> 
      model(
        stlf = decomposition_model(
          STL(log(price) ~ season(window = "periodic"), robust = TRUE),
          RW(season_adjust ~ drift())
        )
      )

gdp_fit_dcmp
```

```{r}
gdp_fit <- gdp_fit |> 
  left_join(gdp_fit_dcmp)
```

```{r}
gdp_fit |> 
  accuracy() |> 
  select(symbol:.type, MAPE, RMSE, MAE, MASE) |> 
  arrange(MAPE)
```

```{r}
gdp_fit |> 
  select(stlf) |> 
  gg_tsresiduals()
```

```{r}
gdp_fit |> 
  augment() |> 
  features(.innov, ljung_box)
```

```{r}
gdp_fc <- gdp_fit |> 
  forecast(h = 6) 

gdp_fc
```

```{r}
gdp_fc |> 
  autoplot(gdp) +
  facet_wrap(~.model, ncol = 1)
```

```{r}
gdp_fc |> 
  filter(.model == "stlf") |> 
  autoplot(gdp)
```

```{r}
gdp_fc |> 
  accuracy(gdp) |> 
  select(.model:.type, MAPE, RMSE, MAE, MASE) |> 
  arrange(MAPE)
```

```{r}
gdp_fit2 <- gdp |> 
  model(
    stlf = decomposition_model(
          STL(log(price) ~ season(window = "periodic"), robust = TRUE),
          RW(season_adjust ~ drift())
        )
  )
gdp_fit2
```

```{r}
gdp_fc_fut <- gdp_fit2 |> 
  forecast(h = "3 years")
gdp_fc_fut
```

```{r}
gdp_fc_fut |> 
  autoplot(gdp)
```

## **Cross Validation**
```{r}
gdp_cv <- gdp |> 
  stretch_tsibble(.init = 60, .step = 4)

cv_results <- gdp_cv |> 
  model(
    arima_cv = ARIMA(log(price))
  ) |> 
  forecast(h = 4) |> 
  accuracy(gdp)

cv_results |> select(.model, MAPE, RMSE, MAE) |> arrange(MAPE)
```

## **ETS Model**
```{r}
gdp_fit_ets <- gdp |> 
  model(ets = ETS(log(price)))

gdp_fc_ets <- gdp_fit_ets |> 
  forecast(h = "3 years")
gdp_fc_ets |> autoplot(gdp)
```

## **Randy del Bosque**
```{r}
gdp_rf_data <- gdp |> 
  mutate(lag1 = lag(price, 1), lag2 = lag(price, 2)) |> 
  drop_na()

rf_model <- randomForest(price ~ lag1 + lag2, data = as_tibble(gdp_rf_data), na.action = na.omit)

rf_predictions <- predict(rf_model, newdata = as_tibble(gdp_rf_data))

rf_results <- tibble(
  date = gdp_rf_data$date,
  actual = gdp_rf_data$price,
  predicted = rf_predictions
)

rf_results |> ggplot(aes(x = date)) +
  geom_line(aes(y = actual, color = "Actual")) +
  geom_line(aes(y = predicted, color = "Predicted")) +
  ggtitle("Random Forest Predictions")

# pura experimentación, no sé si sea adecuado utilizarlo para predecir este tipo de movimientos 
rf_metrics <- tibble(
  .model = "Random Forest",
  MAPE = mean(abs((rf_results$actual - rf_results$predicted) / rf_results$actual)) * 100,
  RMSE = sqrt(mean((rf_results$actual - rf_results$predicted)^2)),
  MAE = mean(abs(rf_results$actual - rf_results$predicted))
)
```

### **ARIMA con Parámetros Específicos**
```{r}
gdp_fit_arima_manual <- gdp |> 
  model(
    arima_manual = ARIMA(log(price) ~ pdq(2,1,2) + PDQ(1,1,1))
  )
gdp_fit_arima_manual
```

```{r}
gdp_fc_arima_manual <- gdp_fit_arima_manual |> 
  forecast(h = "3 years")
gdp_fc_arima_manual |> autoplot(gdp)
```

### **SARIMA (ARIMA con Estacionalidad)**
```{r}
gdp_fit_sarima <- gdp |> 
  model(
    sarima = ARIMA(log(price) ~ pdq(2,1,2) + PDQ(1,1,1, period = 4))
  )
gdp_fit_sarima
```

```{r}
gdp_fc_sarima <- gdp_fit_sarima |> 
  forecast(h = "3 years")
gdp_fc_sarima |> autoplot(gdp)
```

### **Comparación de Modelos**
```{r}
accuracy_comparison <- bind_rows(
  accuracy(gdp_fit_arima_manual),
  accuracy(gdp_fit_sarima),
  accuracy(gdp_fit_ets),
  rf_metrics
) |> 
  select(.model, MAPE, RMSE, MAE) |> 
  arrange(MAPE)

accuracy_comparison
```


Nos gustaba más el Seasonal ARIMA para un resultado mejor pero los resultados son iguales para el arima y el sarima, el arima auto no nos gustó porque el resultado seguía siendo muy cónico y se abría demasiado hacia arriba por la misma tendencia. Los ARIMA son buenos porque fueron diseñados tal cual para manejar dependencias temporales y cómo los datos del pasado influyen en el futuro. Implementamos cross validation en un arima pero los resultados fueron bastante peores. 

De igual manera experimentamos con random forest para ver qué tan accurate resultaba ser. Nos sorprendió la precisión, pero como vimos la función en un foro de reddit (en el cual por cierto indicaba que era particularmente bueno para situaciones con valores faltantes no reparables) no supimos cómo adaptarlo para que se viera de la misma manera que las otras gráficas, hasta donde sé es un tanto riesgoso en este tipo de predicciones porque al no necesitar estacionalidad y no tener fuertes relaciones lineales, no hace caso a la estructura secuencial de los datos. 

El ETS no fue mejor que los arimas, no lo conozco bien pero según chatgpt no debe descartarse como una buena opción porque es bueno con tendencias y valores estacionales. Si no podemos quedarnos con random forest elegiríamos ARIMA, creemos que SARIMA regresa datos iguales porque aunque hay tendencia, la estacionalidad no es fuertísima.
